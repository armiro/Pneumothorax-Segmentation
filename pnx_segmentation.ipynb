{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pnx_segmentation.ipynb",
      "provenance": [],
      "mount_file_id": "1Wyk5wH0NME7DOqDcUk9kfsF6cvinK-Ve",
      "authorship_tag": "ABX9TyPAId9hZITefUbUjjHFz03n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armiro/Pneumothorax-Segmentation/blob/master/pnx_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJscGpINx2zR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import glob, cv2, gzip, gc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Input, Flatten, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, MaxPooling2D, concatenate, Lambda\n",
        "from tensorflow.keras import Model, backend as K, callbacks as cb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br_mHbntybgn",
        "outputId": "de4864dd-247a-4873-ed91-b9579c171601"
      },
      "source": [
        "# load the dataset\n",
        "path = '/content/drive/MyDrive/Datasets/siim_acr_pneumothorax_seg/'\n",
        "img_file = gzip.GzipFile(filename=path+'training_images.npy.gz', mode='r')\n",
        "%time images = np.load(file=img_file)\n",
        "msk_file = gzip.GzipFile(filename=path+'training_masks_resized.npy.gz', mode='r')\n",
        "%time masks = np.load(file=msk_file)\n",
        "metadata = pd.read_csv(filepath_or_buffer=path+'converted-train-rle.csv', index_col=None)\n",
        "age = metadata.loc[:, 'PatientAge']\n",
        "sex = metadata.loc[:, 'PatientSex']\n",
        "view = metadata.loc[:, 'ImageView']\n",
        "\n",
        "print('metadata columns:', metadata.columns)\n",
        "print('shape of the dataset:', images.shape)\n",
        "print('shape of the masks:', masks.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27.2 s, sys: 1.38 s, total: 28.6 s\n",
            "Wall time: 54.9 s\n",
            "CPU times: user 8.39 s, sys: 1.39 s, total: 9.78 s\n",
            "Wall time: 9.82 s\n",
            "metadata columns: Index(['ImageId', 'PatientId', 'PatientAge', 'PatientSex', 'ImageView'], dtype='object')\n",
            "shape of the dataset: (12047, 512, 512)\n",
            "shape of the masks: (12047, 512, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tJhrEQ6Xw9X"
      },
      "source": [
        "# because of memory limit, manual data splitter is defined so that we can split \n",
        "# images and masks in different steps and delete unnecessary variables in between\n",
        "def manual_train_test_split(data, test_ratio, init_indices):\n",
        "    if init_indices is not None:\n",
        "        shuffle_indices = init_indices\n",
        "    else:\n",
        "        shuffle_indices = np.random.permutation(len(data))\n",
        "    test_size = int(test_ratio * len(data))\n",
        "    test_indices = shuffle_indices[:test_size]\n",
        "    train_indices = shuffle_indices[test_size:]\n",
        "    return data[train_indices], data[test_indices], shuffle_indices\n",
        "\n",
        "\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "X_train, X_val, indices = manual_train_test_split(data=images, test_ratio=0.2, init_indices=None)\n",
        "del images\n",
        "gc.collect()\n",
        "\n",
        "masks = np.expand_dims(masks, axis=-1)\n",
        "y_train, y_val, _ = manual_train_test_split(data=masks, test_ratio=0.2, init_indices=indices)\n",
        "del masks\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ4dw-lK2f8P"
      },
      "source": [
        "# define metrics: dice coefficient (DICE/F1-score) and intersection over union (IoU/Jaccard)\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    overlap = K.sum(K.abs(y_true * y_pred), axis=[1, 2, 3])\n",
        "    total_area = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n",
        "    dsc = K.mean((2.0 * overlap + smooth) / (total_area + smooth), axis=0)\n",
        "    return dsc\n",
        "\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1, 2, 3])\n",
        "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3]) - intersection\n",
        "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "    return iou"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "cPEpYSb_uz0z",
        "outputId": "2ac45ffa-51d4-4715-be12-bec6cebf3624"
      },
      "source": [
        "# test masks to see if both DSC ans IoU metrics are working correctly\n",
        "im1 = np.expand_dims(y_train[2], axis=0).astype('float64')\n",
        "im2 = np.expand_dims(y_train[29], axis=0).astype('float64')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(X=np.squeeze(im1, axis=(0, -1)), cmap='gray')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(X=np.squeeze(im2, axis=(0, -1)), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('inter-dice is:', dice_coef(im1, im2), 'and inter-jaccard is:', iou_coef(im1, im2))\n",
        "print('self-dice is:', dice_coef(im1, im1), 'and self-jaccard is:', iou_coef(im1, im1))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "inter-dice is: tf.Tensor(1.0, shape=(), dtype=float64) and inter-jaccard is: tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "self-dice is: tf.Tensor(1.0, shape=(), dtype=float64) and self-jaccard is: tf.Tensor(1.0, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TV4kG59yLi6"
      },
      "source": [
        "# model architecture: vanilla unet\n",
        "def vanilla_unet(input_size=(512,512,1)):\n",
        "    inputs = Input(input_size)\n",
        "    ds_inputs = Lambda(lambda image: image/255.0, name='down_scaler')(inputs)\n",
        "    \n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(ds_inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[conv10], name='segmentor')\n",
        "\n",
        "\n",
        "model = vanilla_unet(input_size=(512, 512, 1))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, iou_coef])\n",
        "model.summary()\n",
        "# tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnl_J7VxZEhg"
      },
      "source": [
        "# define training callbacks\n",
        "checkpoint = cb.ModelCheckpoint('/content/drive/My Drive/pnx_model/eps={epoch:03d}_valLoss={val_loss:.4f}.hdf5',\n",
        "                                monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "cb_list = [checkpoint]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYdImdn1wygW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3a243c-1bda-4b58-a83c-9954614affe5"
      },
      "source": [
        "training = model.fit(x=X_train, y=y_train, batch_size=24, epochs=1, verbose=1,\n",
        "                     steps_per_epoch=len(X_train)//24.0, validation_data=(X_val, y_val),\n",
        "                     callbacks=cb_list)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(training.history['loss'], color='r', label='training_loss')\n",
        "plt.plot(training.history['val_loss'], color='g', label='validation_loss')\n",
        "plt.legend()\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(training.history['dice_coef'], color='r', label='training_dsc')\n",
        "plt.plot(training.history['val_dice_coef'], color='g', label='validation_dsc')\n",
        "plt.legend()\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(training.history['iou_coef'], color='r', label='training_iou')\n",
        "plt.plot(training.history['val_iou_coef'], color='g', label='validation_iou')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig.savefig('/content/drive/My Drive/pnx_model/training.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2/401 [..............................] - ETA: 3:25 - loss: 0.6869 - dice_coef: 0.0043 - iou_coef: 0.0022WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2679s vs `on_train_batch_end` time: 0.7516s). Check your callbacks.\n",
            " 63/401 [===>..........................] - ETA: 5:48 - loss: 0.0918 - dice_coef: 0.0031 - iou_coef: 0.0024"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pacpViTZMeZZ"
      },
      "source": [
        "idx = 17\n",
        "\n",
        "plt.imshow(X=X_train[idx].squeeze(), cmap='bone')\n",
        "plt.show()\n",
        "plt.imshow(X=y_train[idx].squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "pred = model.predict(np.expand_dims(X_train[idx], axis=0))\n",
        "plt.imshow(X=np.squeeze(pred, axis=(0, -1)), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}